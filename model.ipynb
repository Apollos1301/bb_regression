{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from torchvision.models import googlenet, GoogLeNet_Weights, mobilenet_v3_small, MobileNet_V3_Small_Weights, vgg16, VGG16_Weights\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device) \n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_imgs = []\n",
    "\n",
    "data_train_c = []\n",
    "classes_train_c = []\n",
    "data_train_r = []\n",
    "classes_train_r = []\n",
    "bounds_train = []\n",
    "\n",
    "data_test = []\n",
    "classes_test = []\n",
    "\n",
    "img_directories = [\"./data/images/butterfly\",\"./data/images/dalmatian\", \"./data/images/dolphin\"]\n",
    "anno_directories = [\"./data/annotations/res_butterfly.txt\",\"./data/annotations/res_dalmatian.txt\", \"./data/annotations/res_dolphin.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESIZE = 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_transformer_1 = transforms.Compose([\n",
    "                           transforms.Resize((RESIZE, RESIZE)),\n",
    "                           transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "                           transforms.RandomRotation(5),\n",
    "                           transforms.RandomAffine(degrees=11, translate=(0.1,0.1), scale=(0.8,0.8)),\n",
    "                           transforms.ToTensor(),\n",
    "]),\n",
    "\n",
    "class_transformer_2 = transforms.Compose([\n",
    "                                 transforms.Resize((RESIZE, RESIZE)),\n",
    "                                 transforms.RandomHorizontalFlip(),\n",
    "                                 transforms.RandomRotation(10),\n",
    "                                 transforms.RandomAffine(translate=(0.05,0.05), degrees=0),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.RandomErasing(inplace=True, scale=(0.01, 0.23))]),\n",
    "\n",
    "transformers = [class_transformer_1, class_transformer_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\DeepL\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\DeepL\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\DeepL\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for idx, dirr in enumerate(img_directories):\n",
    "    data = pd.read_csv(anno_directories[idx], delimiter=',', header=None)\n",
    "    for idx_2, filename in enumerate(os.listdir(dirr)):\n",
    "        if(idx_2 < 65):\n",
    "            classes_train_c.append(idx)\n",
    "            classes_train_r.append(idx)\n",
    "\n",
    "            full_path = os.path.join(dirr, filename)\n",
    "            img = Image.open(full_path)\n",
    "            \n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "            \n",
    "            img_ = transforms.ToTensor()(img)\n",
    "\n",
    "            h, w = img_.shape[1:]\n",
    "            img_ = transforms.Resize(size=(RESIZE,RESIZE))(img_)\n",
    "            \n",
    "            x1,y1,x2,y2 = data.iloc[idx_2,1:].values\n",
    "            x1 = (x1 * RESIZE) / w\n",
    "            y1 = (y1 * RESIZE) / h\n",
    "            x2 = (x2 * RESIZE) / w\n",
    "            y2 = (y2 * RESIZE) / h\n",
    "            \n",
    "            bounds_train.append((x1,y1,x2,y2))\n",
    "            data_train_c.append(img_)\n",
    "            data_train_r.append(img_)\n",
    "            \n",
    "            img_1_c = transformers[0][0](img)\n",
    "            img_2_c = transformers[1][0](img)\n",
    "            \n",
    "            data_train_c.append(img_1_c)\n",
    "            data_train_c.append(img_2_c)\n",
    "            classes_train_c.append(idx)\n",
    "            classes_train_c.append(idx)\n",
    "        else:\n",
    "            \n",
    "            classes_test.append(idx)\n",
    "            \n",
    "            full_path = os.path.join(dirr, filename)\n",
    "            img = Image.open(full_path)\n",
    "            raw_imgs.append(img)\n",
    "            img = transforms.ToTensor()(img)\n",
    "            img = transforms.Resize(size=(RESIZE,RESIZE))(img)\n",
    "            data_test.append(img)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageData(Dataset):\n",
    "    def __init__(self, X, labels, b_enabled , width, bounds = []):\n",
    "        super(ImageData, self).__init__()\n",
    "        self.X = X\n",
    "        self.labels = labels\n",
    "        self.b_enabled = b_enabled\n",
    "        if(self.b_enabled):\n",
    "            self.bounds = bounds\n",
    "        \n",
    "        self.width = width\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = self.X[idx].float()\n",
    "        label = self.labels[idx]\n",
    "        label = torch.tensor(label).float()\n",
    "        if(self.b_enabled):\n",
    "            x1,y1,x2,y2 = self.bounds[idx]\n",
    "            x1 = x1 / self.width\n",
    "            x2 = x2 / self.width\n",
    "            y1 = y1 / self.width\n",
    "            y2 = y2 / self.width\n",
    "\n",
    "            bounds = torch.tensor([x1,y1,x2,y2]).float()\n",
    "            return X, label, bounds\n",
    "        return X, label\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Dataset_r = ImageData(data_train_r, classes_train_r, True, RESIZE, bounds_train)\n",
    "train_Dataset_c = ImageData(data_train_c, classes_train_c, False, RESIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "train_loader_r = DataLoader(train_Dataset_r, batch_size=BATCH_SIZE, shuffle=True)\n",
    "train_loader_c = DataLoader(train_Dataset_c, batch_size=BATCH_SIZE, shuffle=True)\n",
    "print(len(train_loader_c))\n",
    "print(len(train_loader_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, num_classes = 3, num_bounds = 4):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size = 5, stride=3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(32,64, kernel_size = 5, stride = 3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2,2),\n",
    "        )\n",
    "        self.classification = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512,124),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(124, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,num_classes),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.regression = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512,124),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(124, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,num_bounds),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_ = self.features(x)\n",
    "        return (self.classification(x_), self.regression(x_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel().to(device=device)\n",
    "\n",
    "\n",
    "# optimizer_c = optim.SGD(model.classification.parameters(), lr=1e-3, momentum=0.9)\n",
    "# optimizer_r = optim.SGD(model.regression.parameters(), lr=1e-2)\n",
    "\n",
    "# scheduler_c = lr_scheduler.ReduceLROnPlateau(optimizer_c, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "# scheduler_r = lr_scheduler.ReduceLROnPlateau(optimizer_r, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn_c = nn.CrossEntropyLoss()\n",
    "loss_fn_r = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_model():"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_values_c = []\n",
    "loss_values_r = []\n",
    "\n",
    "acc_values_c = []\n",
    "acc_values_r = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    total_loss_c = 0\n",
    "    total_loss_r = 0\n",
    "    for X, label, bounds in train_loader_c:\n",
    "        # optimizer_c.zero_grad()\n",
    "        # optimizer_r.zero_grad()\n",
    "        \n",
    "        X = X.to(device)\n",
    "        bounds = bounds.to(device)\n",
    "        \n",
    "        class_ = torch.zeros(3).to(device)\n",
    "        class_[int(label.item())] = 1\n",
    "        \n",
    "        pred_class, pred_bounds = model(X)\n",
    "        pred_class = pred_class.view(-1)\n",
    "        \n",
    "        loss_c = loss_fn_c(pred_class, class_)\n",
    "        loss_r = loss_fn_r(pred_bounds, bounds)\n",
    "        \n",
    "        loss = loss_c + loss_r  # Adjust weights as needed\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # loss_c = loss_fn_c(pred_class, class_)\n",
    "        # loss_c.backward()\n",
    "        # optimizer_c.step()\n",
    "        \n",
    "        # loss_r = loss_fn_r(pred_bounds, bounds)\n",
    "        # loss_r.backward()\n",
    "        # optimizer_r.step()\n",
    "        \n",
    "        \n",
    "        total_loss_c += loss_c.item()\n",
    "        total_loss_r += loss_r.item()\n",
    "        \n",
    "    avg_loss_c = total_loss_c / len(train_loader_c)\n",
    "    loss_values_c.append(avg_loss_c)\n",
    "    \n",
    "    # scheduler_c.step(avg_loss_c)\n",
    "    \n",
    "    avg_loss_r = total_loss_r / len(train_loader_c)\n",
    "    loss_values_r.append(avg_loss_r)\n",
    "    \n",
    "    # scheduler_r.step(avg_loss_r)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1}/{NUM_EPOCHS}')\n",
    "    print(f'classification loss: {avg_loss_c}')\n",
    "    print(f'regression loss: {avg_loss_r}')\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_model = vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n",
    "# for param in pre_model.parameters():\n",
    "#     param.requires_grad=False\n",
    "# pre_model.classifier[6] = nn.Linear(in_features=pre_model.classifier[6].in_features, out_features=pre_model.classifier[6].out_features)\n",
    "features = list(pre_model.features)\n",
    "classifier = list(pre_model.classifier[:-1])\n",
    "classifier.insert(0, nn.Flatten())\n",
    "classifier.insert(0, nn.AdaptiveAvgPool2d((7, 7)))\n",
    "classifier[2] = nn.Linear(in_features=25088, out_features=4096)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_head = nn.Sequential(\n",
    "    *classifier,\n",
    "    nn.Linear(4096, 3),\n",
    "    # nn.Softmax()\n",
    ")\n",
    "\n",
    "# Bounding box regression head\n",
    "bbox_head = nn.Sequential(\n",
    "    *classifier,\n",
    "    nn.Linear(4096, 4),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomVGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomVGG16, self).__init__()\n",
    "        self.features = nn.Sequential(*features)\n",
    "        self.classifier = classification_head\n",
    "        self.bbox_regressor = bbox_head\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        class_output = self.classifier(x)\n",
    "        bbox_output = self.bbox_regressor(x)\n",
    "        return class_output, bbox_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_model = CustomVGG16().to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train (Head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in comb_model.parameters():\n",
    "    param.requires_grad=False\n",
    "for param in comb_model.classifier.parameters():\n",
    "    param.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_c = optim.Adam(comb_model.classifier.parameters(), lr=1e-3)\n",
    "loss_fn_c = nn.CrossEntropyLoss()\n",
    "scheduler_c = lr_scheduler.ReduceLROnPlateau(optimizer_c, mode='min', factor=0.1, patience=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_values_c = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    total_loss_c = 0\n",
    "    for X, label in train_loader_c:\n",
    "        \n",
    "        X = X.to(device)\n",
    "        label = label.long().to(device)\n",
    "        \n",
    "        pred_class, pred_bounds = comb_model(X)\n",
    "        \n",
    "        loss_c = loss_fn_c(pred_class, label)\n",
    "        \n",
    "        optimizer_c.zero_grad()\n",
    "        loss_c.backward()\n",
    "        optimizer_c.step()\n",
    "        \n",
    "        \n",
    "        total_loss_c += loss_c.item()\n",
    "        \n",
    "    avg_loss_c = total_loss_c / len(train_loader_c)\n",
    "    loss_values_c.append(avg_loss_c)\n",
    "    \n",
    "    scheduler_c.step(avg_loss_c)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1}/{NUM_EPOCHS}')\n",
    "    print(f'classification loss: {avg_loss_c}')\n",
    "    # print(f'lr: {scheduler_c.get_last_lr()}')\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(loss_values_c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regression head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in comb_model.parameters():\n",
    "    param.requires_grad=False\n",
    "for param in comb_model.bbox_regressor.parameters():\n",
    "    param.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_r = optim.Adam(comb_model.bbox_regressor.parameters(), lr=1e-3)\n",
    "loss_fn_r = nn.MSELoss()\n",
    "scheduler_r = lr_scheduler.ReduceLROnPlateau(optimizer_r, mode='min', factor=0.1, patience=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_values_r = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    total_loss_r = 0\n",
    "    for X, label, bounds in train_loader_r:\n",
    "        \n",
    "        X = X.to(device)\n",
    "        bounds = bounds.to(device)\n",
    "        \n",
    "        pred_class, pred_bounds = comb_model(X)\n",
    "        \n",
    "        loss_r = loss_fn_r(pred_bounds, bounds)\n",
    "\n",
    "        optimizer_r.zero_grad()\n",
    "        loss_r.backward()\n",
    "        optimizer_r.step()\n",
    "        \n",
    "        total_loss_r += loss_r.item()\n",
    "    \n",
    "    avg_loss_r = total_loss_r / len(train_loader_r)\n",
    "    loss_values_r.append(avg_loss_r)\n",
    "    \n",
    "    scheduler_r.step(avg_loss_r)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1}/{NUM_EPOCHS}')\n",
    "    print(f'regression loss: {avg_loss_r}')\n",
    "    # print(f'lr: {scheduler_r.get_last_lr()}')\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(loss_values_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train (Finetuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in comb_model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(comb_model.parameters(), lr=1e-4)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "loss_fn_c = nn.CrossEntropyLoss()\n",
    "loss_fn_r = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader = [train_loader_c, train_loader_r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/40\n",
      "total loss: 0.9534002404946548\n",
      "classification loss: 0.8638879748491141\n",
      "regression loss: 0.08951225597411394\n",
      "Epoch: 2/40\n",
      "total loss: 0.32379921754965413\n",
      "classification loss: 0.30623615361177003\n",
      "regression loss: 0.017563065513968468\n",
      "Epoch: 3/40\n",
      "total loss: 0.04654226301667782\n",
      "classification loss: 0.031433509597823456\n",
      "regression loss: 0.015108752709168654\n",
      "Epoch: 4/40\n",
      "total loss: 0.16451781228757822\n",
      "classification loss: 0.1472836243158851\n",
      "regression loss: 0.017234186856792524\n",
      "Epoch: 5/40\n",
      "total loss: 0.04308793801241196\n",
      "classification loss: 0.03033539736106132\n",
      "regression loss: 0.012752540588665467\n",
      "Epoch: 6/40\n",
      "total loss: 0.014547628780397085\n",
      "classification loss: 0.0020239291924763867\n",
      "regression loss: 0.012523699623460952\n",
      "Epoch: 7/40\n",
      "total loss: 0.013355825597850176\n",
      "classification loss: 0.0006880749588862483\n",
      "regression loss: 0.012667750653166037\n",
      "Epoch: 8/40\n",
      "total loss: 0.012316697778610082\n",
      "classification loss: 0.00031960679091123614\n",
      "regression loss: 0.011997091082426218\n",
      "Epoch: 9/40\n",
      "total loss: 0.01222074475999062\n",
      "classification loss: 0.0003249501563774314\n",
      "regression loss: 0.011895794564714799\n",
      "Epoch: 10/40\n",
      "total loss: 0.010335092110416064\n",
      "classification loss: 0.00037809816813723254\n",
      "regression loss: 0.009956993950674167\n",
      "Epoch: 11/40\n",
      "total loss: 0.00977841943788987\n",
      "classification loss: 0.0003436233561772567\n",
      "regression loss: 0.009434796117532711\n",
      "Epoch: 12/40\n",
      "total loss: 0.008832949177863507\n",
      "classification loss: 0.0005001722098453543\n",
      "regression loss: 0.008332776872871013\n",
      "Epoch: 13/40\n",
      "total loss: 0.008856422267854214\n",
      "classification loss: 0.0004339282696981592\n",
      "regression loss: 0.008422493934631348\n",
      "Epoch: 14/40\n",
      "total loss: 0.007987110875546932\n",
      "classification loss: 0.0005063250553995693\n",
      "regression loss: 0.007480785931245639\n",
      "Epoch: 15/40\n",
      "total loss: 0.007830336439208342\n",
      "classification loss: 0.0005835868376799716\n",
      "regression loss: 0.007246749511418434\n",
      "Epoch: 16/40\n",
      "total loss: 0.007065366452129988\n",
      "classification loss: 0.0002675770721487844\n",
      "regression loss: 0.006797789381100581\n",
      "Epoch: 17/40\n",
      "total loss: 0.006314761685923888\n",
      "classification loss: 0.00041962347033684357\n",
      "regression loss: 0.005895138216706423\n",
      "Epoch: 18/40\n",
      "total loss: 0.0057118435820134785\n",
      "classification loss: 0.00025609582035730663\n",
      "regression loss: 0.005455747712403536\n",
      "Epoch: 19/40\n",
      "total loss: 0.005551031826493831\n",
      "classification loss: 0.00031228460899840755\n",
      "regression loss: 0.005238747242121742\n",
      "Epoch: 20/40\n",
      "total loss: 0.0056291647936002566\n",
      "classification loss: 0.0003010517964587332\n",
      "regression loss: 0.005328113034081001\n",
      "Epoch: 21/40\n",
      "total loss: 0.0045520017783229165\n",
      "classification loss: 0.0003778505493895724\n",
      "regression loss: 0.00417415126083562\n",
      "Epoch: 22/40\n",
      "total loss: 0.0051071613919563014\n",
      "classification loss: 0.00031749437934754847\n",
      "regression loss: 0.004789667060742011\n",
      "Epoch: 23/40\n",
      "total loss: 0.004524365300312638\n",
      "classification loss: 0.00032332716196273954\n",
      "regression loss: 0.0042010381674537295\n",
      "Epoch: 24/40\n",
      "total loss: 0.004108015143384154\n",
      "classification loss: 0.00023978688785483918\n",
      "regression loss: 0.003868228326050135\n",
      "Epoch: 25/40\n",
      "total loss: 0.004315827740356326\n",
      "classification loss: 0.00032160487787153287\n",
      "regression loss: 0.003994222873678574\n",
      "Epoch: 26/40\n",
      "total loss: 0.003914507965628917\n",
      "classification loss: 0.0002957948062640543\n",
      "regression loss: 0.003618713181752425\n",
      "Epoch: 27/40\n",
      "total loss: 0.0038543677566429744\n",
      "classification loss: 0.0001675642874593345\n",
      "regression loss: 0.003686803482616177\n",
      "Epoch: 28/40\n",
      "total loss: 0.003203410279149046\n",
      "classification loss: 0.0001611455786937418\n",
      "regression loss: 0.003042264716126598\n",
      "Epoch: 29/40\n",
      "total loss: 0.0038904497005905095\n",
      "classification loss: 0.00023303194169644624\n",
      "regression loss: 0.0036574177658901764\n",
      "Epoch: 30/40\n",
      "total loss: 0.003228491279654778\n",
      "classification loss: 0.00018803719187697145\n",
      "regression loss: 0.003040454090716174\n",
      "Epoch: 31/40\n",
      "total loss: 0.0033648280211939262\n",
      "classification loss: 0.0001228206572425104\n",
      "regression loss: 0.003242007402989727\n",
      "Epoch: 32/40\n",
      "total loss: 0.0028293161975363125\n",
      "classification loss: 0.0002414921725106139\n",
      "regression loss: 0.0025878240121528506\n",
      "Epoch: 33/40\n",
      "total loss: 0.0031245907482046345\n",
      "classification loss: 0.00014720841136295348\n",
      "regression loss: 0.0029773823200510098\n",
      "Epoch: 34/40\n",
      "total loss: 0.002757855601465473\n",
      "classification loss: 9.990921423125725e-05\n",
      "regression loss: 0.0026579463603691412\n",
      "Epoch: 35/40\n",
      "total loss: 0.0025331332491567503\n",
      "classification loss: 0.00017954275398761427\n",
      "regression loss: 0.0023535904922307683\n",
      "Epoch: 36/40\n",
      "total loss: 0.002643688510243709\n",
      "classification loss: 0.00013880514290156917\n",
      "regression loss: 0.0025048833429956664\n",
      "Epoch: 37/40\n",
      "total loss: 0.0024721458858738723\n",
      "classification loss: 0.00016959811742148863\n",
      "regression loss: 0.0023025477645345605\n",
      "Epoch: 38/40\n",
      "total loss: 0.0025583255158450743\n",
      "classification loss: 0.00015020221004446145\n",
      "regression loss: 0.0024081233512753476\n",
      "Epoch: 39/40\n",
      "total loss: 0.0024268226608490716\n",
      "classification loss: 0.00013566746831482026\n",
      "regression loss: 0.0022911551820400814\n",
      "Epoch: 40/40\n",
      "total loss: 0.002470784937031567\n",
      "classification loss: 0.000166459080691521\n",
      "regression loss: 0.0023043258473850214\n"
     ]
    }
   ],
   "source": [
    "loss_val = []\n",
    "loss_values_c = []\n",
    "loss_values_r = []\n",
    "weight_cls = 1.0\n",
    "weight_reg = 1.0\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    total_loss_c = 0\n",
    "    total_loss_r = 0\n",
    "    total_loss = 0\n",
    "    for X, label, bounds in train_loader_r:\n",
    "        # optimizer_c.zero_grad()\n",
    "        # optimizer_r.zero_grad()\n",
    "        \n",
    "        X = X.to(device)\n",
    "        bounds = bounds.to(device)\n",
    "        \n",
    "        label = label.long().to(device)\n",
    "        \n",
    "        pred_class, pred_bounds = comb_model(X)\n",
    "        \n",
    "        loss_c = loss_fn_c(pred_class, label)\n",
    "        loss_r = loss_fn_r(pred_bounds, bounds)\n",
    "        \n",
    "        loss = weight_cls * loss_c + weight_reg * loss_r  # Adjust weights as needed\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss_c += loss_c.item() * weight_cls\n",
    "        total_loss_r += loss_r.item() * weight_reg\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    avg_loss_c = total_loss_c / len(train_loader_r)\n",
    "    loss_values_c.append(avg_loss_c)\n",
    "    \n",
    "    # scheduler_c.step(avg_loss_c)\n",
    "    \n",
    "    avg_loss_r = total_loss_r / len(train_loader_r)\n",
    "    loss_values_r.append(avg_loss_r)\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader_r)\n",
    "    loss_val.append(avg_loss)\n",
    "    scheduler.step(avg_loss)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1}/{NUM_EPOCHS}')\n",
    "    # print(f'learning rate: {scheduler.get_last_lr()}')\n",
    "    print(f'total loss: {avg_loss}')\n",
    "    print(f'classification loss: {avg_loss_c}')\n",
    "    print(f'regression loss: {avg_loss_r}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(loss_values_c)\n",
    "plt.plot(loss_values_r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1: 112.92843627929688, y1: 47.859291076660156\n",
      "x2: 468.1951599121094, y2: 177.5253143310547\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "comb_model.eval()\n",
    "idx = 8\n",
    "\n",
    "myImg = Image.open(\"./data/tests/img_3.jpg\")\n",
    "img = transforms.ToTensor()(myImg)\n",
    "h, w = img.shape[1:]\n",
    "img = transforms.Resize(size=(RESIZE,RESIZE))(img)\n",
    "\n",
    "# x1,y1,x2,y2 = data.iloc[idx_2,1:].values\n",
    "\n",
    "with torch.no_grad():\n",
    "    x = img.to(device)\n",
    "    # x = data_test[idx].to(device)\n",
    "    x = x.unsqueeze(0)\n",
    "    # class_ = classes_test[idx]\n",
    "    pred_class, pred_bounds = comb_model(x)\n",
    "    x1,y1,x2,y2 = pred_bounds[0][0],pred_bounds[0][1],pred_bounds[0][2],pred_bounds[0][3]\n",
    "    # w, h = raw_imgs[idx].size\n",
    "    x1 = x1 * w\n",
    "    y1 = y1 * h\n",
    "    x2 = x2 * w\n",
    "    y2 = y2 * h\n",
    "    \n",
    "    draw = ImageDraw.Draw(myImg)\n",
    "    print(f'x1: {x1}, y1: {y1}')\n",
    "    print(f'x2: {x2}, y2: {y2}')\n",
    "    print(torch.argmax(pred_class).item())\n",
    "    top_left = (x1, y1)\n",
    "    bottom_right = (x2, y2) \n",
    "    \n",
    "    draw.rectangle([top_left, bottom_right], outline=\"red\", width=3)\n",
    "    \n",
    "    myImg.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label, bounds = next(iter(train_loader_r))\n",
    "data = data.to(device)\n",
    "comb_model.eval()\n",
    "with torch.no_grad():\n",
    "    pre_cl, pred_bounds = comb_model(data)\n",
    "    print(pred_bounds)\n",
    "    print(bounds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
